"""
Demonstra√ß√£o do Sistema de Valida√ß√£o de Roteiros - AiShorts v2.0

Este script demonstra as funcionalidades do sistema de valida√ß√£o,
incluindo valida√ß√£o para m√∫ltiplas plataformas e gera√ß√£o de relat√≥rios.
"""

import sys
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

# Adiciona o diret√≥rio src ao path
sys.path.append(str(Path(__file__).parent / "src"))

from src.validators.script_validator import (
    ScriptValidator, PlatformType, ValidationSeverity, QualityLevel
)
from src.generators.script_generator import GeneratedScript, ScriptSection
from src.generators.theme_generator import GeneratedTheme
from src.generators.prompt_engineering import ThemeCategory


def create_sample_scripts() -> Dict[str, GeneratedScript]:
    """Cria roteiros de exemplo para demonstra√ß√£o."""
    
    scripts = {}
    
    # 1. Roteiro de qualidade alta
    print("üìù Criando roteiro de qualidade alta...")
    
    theme_high = GeneratedTheme(
        content="Mist√©rios dos oceanos profundos",
        category=ThemeCategory.SCIENCE,
        quality_score=0.9,
        response_time=2.5,
        timestamp=datetime.now()
    )
    
    hook_high = ScriptSection(
        name="hook",
        content="Voc√™ sabia que existem criaturas nos oceanos que brilham no escuro? Esses seres incr√≠veis est√£o a milhares de metros de profundidade!",
        duration_seconds=18,
        purpose="Captar aten√ß√£o com curiosidade",
        key_elements=["pergunta", "criaturas", "bioluminesc√™ncia"]
    )
    
    development_high = ScriptSection(
        name="development",
        content="Esses organismos usam bioluminesc√™ncia para ca√ßar, se comunicar e se defender. Estudos recentes mostram que 80% das criaturas marinhas em √°guas profundas possuem essa capacidade incr√≠vel. Pesquisadores descobriram que essa luz √© produced por uma rea√ß√£o qu√≠mica chamada luciferina.",
        duration_seconds=63,
        purpose="Explicar o fen√¥meno cient√≠fico",
        key_elements=["bioluminesc√™ncia", "estudos", "luciferina"]
    )
    
    conclusion_high = ScriptSection(
        name="conclusion",
        content="Incr√≠vel, n√©? Os oceanos ainda guardam muitos segredos! Curtiu esse fato? Compartilha com seus amigos e segue para mais mist√©rios marinhos!",
        duration_seconds=18,
        purpose="Encerrar com engajamento",
        key_elements=["engajamento", "cta", "oceanografia"]
    )
    
    scripts["high_quality"] = GeneratedScript(
        title="Bioluminesc√™ncia Oce√¢nica",
        theme=theme_high,
        sections=[hook_high, development_high, conclusion_high],
        total_duration=99,
        quality_score=0.92,
        engagement_score=0.95,
        retention_score=0.88,
        response_time=3.2,
        timestamp=datetime.now()
    )
    
    # 2. Roteiro de qualidade m√©dia
    print("üìù Criando roteiro de qualidade m√©dia...")
    
    theme_medium = GeneratedTheme(
        content="Fatos sobre o espa√ßo",
        category=ThemeCategory.SPACE,
        quality_score=0.7,
        response_time=2.0,
        timestamp=datetime.now()
    )
    
    hook_medium = ScriptSection(
        name="hook",
        content="O espa√ßo √© muito interessante",
        duration_seconds=10,
        purpose="Hook b√°sico",
        key_elements=["espa√ßo"]
    )
    
    development_medium = ScriptSection(
        name="development",
        content="Existem muitas estrelas no c√©u. Elas s√£o muito brilhantes e bonitas.",
        duration_seconds=50,
        purpose="Desenvolvimento simples",
        key_elements=["estrelas", "c√©u"]
    )
    
    conclusion_medium = ScriptSection(
        name="conclusion",
        content="Espero que tenham gostado",
        duration_seconds=15,
        purpose="Encerrar",
        key_elements=["expectativa"]
    )
    
    scripts["medium_quality"] = GeneratedScript(
        title="Fatos B√°sicos do Espa√ßo",
        theme=theme_medium,
        sections=[hook_medium, development_medium, conclusion_medium],
        total_duration=75,
        quality_score=0.65,
        engagement_score=0.45,
        retention_score=0.55,
        response_time=2.8,
        timestamp=datetime.now()
    )
    
    # 3. Roteiro problem√°tico
    print("üìù Criando roteiro problem√°tico...")
    
    theme_problematic = GeneratedTheme(
        content="Tema gen√©rico",
        category=ThemeCategory.SCIENCE,
        quality_score=0.3,
        response_time=1.5,
        timestamp=datetime.now()
    )
    
    hook_problematic = ScriptSection(
        name="hook",
        content="",  # Conte√∫do vazio - PROBLEMA
        duration_seconds=0,  # Dura√ß√£o zero - PROBLEMA
        purpose="",
        key_elements=[]
    )
    
    development_problematic = ScriptSection(
        name="development",
        content="spam spam spam repeti√ß√£o spam spam spam spam spam repeti√ß√£o spam",  # Muito repetitivo
        duration_seconds=25,
        purpose="",
        key_elements=[]
    )
    
    scripts["problematic"] = GeneratedScript(
        title="Roteiro com Problemas",
        theme=theme_problematic,
        sections=[hook_problematic, development_problematic],
        total_duration=25,
        quality_score=0.25,
        engagement_score=0.15,
        retention_score=0.20,
        response_time=1.5,
        timestamp=datetime.now()
    )
    
    return scripts


def demonstrate_single_platform_validation(validator: ScriptValidator, script: GeneratedScript):
    """Demonstra valida√ß√£o para uma plataforma espec√≠fica."""
    print(f"\nüéØ VALIDANDO PARA TIKTOK")
    print("=" * 50)
    
    report = validator.validate_script(script, PlatformType.TIKTOK)
    
    # Exibe resumo
    print(f"üìä RESUMO DA VALIDA√á√ÉO:")
    print(f"   Plataforma: {report.platform.value}")
    print(f"   Score Geral: {report.overall_score:.2f}/100")
    print(f"   N√≠vel: {report.quality_level.value.upper()}")
    print(f"   Aprovado: {'‚úÖ SIM' if report.is_approved else '‚ùå N√ÉO'}")
    
    # Exibe scores por categoria
    print(f"\nüìà SCORES DETALHADOS:")
    print(f"   Estrutura: {report.structure_validation.score:.1f}/100")
    print(f"   Conte√∫do: {report.content_validation.score:.1f}/100") 
    print(f"   Plataforma: {report.platform_validation.score:.1f}/100")
    
    # Exibe m√©tricas de qualidade
    print(f"\nüéØ M√âTRICAS DE QUALIDADE:")
    print(f"   Clareza: {report.quality_metrics.clarity_score:.2f}")
    print(f"   Engajamento: {report.quality_metrics.engagement_score:.2f}")
    print(f"   Reten√ß√£o: {report.quality_metrics.retention_score:.2f}")
    
    # Exibe problemas encontrados
    if report.all_issues:
        print(f"\n‚ö†Ô∏è  PROBLEMAS ENCONTRADOS ({len(report.all_issues)}):")
        for i, issue in enumerate(report.all_issues[:5], 1):  # Mostra apenas os 5 primeiros
            emoji = "üî¥" if issue.severity == ValidationSeverity.ERROR else "üü°"
            print(f"   {emoji} {issue.code}: {issue.message}")
            if issue.section:
                print(f"      Se√ß√£o: {issue.section}")
    
    # Exibe sugest√µes
    if report.suggestions:
        print(f"\nüí° SUGEST√ïES ({len(report.suggestions)}):")
        for i, suggestion in enumerate(report.suggestions[:3], 1):  # Mostra apenas as 3 primeiras
            print(f"   {i}. {suggestion}")
    
    return report


def demonstrate_multiple_platform_validation(validator: ScriptValidator, script: GeneratedScript):
    """Demonstra valida√ß√£o para m√∫ltiplas plataformas."""
    print(f"\nüåê VALIDA√á√ÉO MULTIPLATAFORMA")
    print("=" * 50)
    
    reports = validator.validate_multiple_platforms(script)
    
    print(f"Roteiro: '{script.title}'\n")
    
    # Cria tabela comparativa
    platforms_data = []
    for platform, report in reports.items():
        platforms_data.append({
            "plataforma": platform.value.upper(),
            "score": f"{report.overall_score:.1f}",
            "n√≠vel": report.quality_level.value,
            "aprovado": "‚úÖ" if report.is_approved else "‚ùå",
            "problemas": len(report.all_issues),
            "sugest√µes": len(report.suggestions)
        })
    
    # Exibe tabela
    print(f"{'Plataforma':<12} {'Score':<8} {'N√≠vel':<10} {'Aprovado':<10} {'Problemas':<10} {'Sugest√µes':<10}")
    print("-" * 70)
    for data in platforms_data:
        print(f"{data['plataforma']:<12} {data['score']:<8} {data['n√≠vel']:<10} {data['aprovado']:<10} {data['problemas']:<10} {data['sugest√µes']:<10}")
    
    # Identifica a melhor plataforma
    best_platform = max(reports.items(), key=lambda x: x[1].overall_score)
    worst_platform = min(reports.items(), key=lambda x: x[1].overall_score)
    
    print(f"\nüèÜ MELHOR PLATAFORMA: {best_platform[0].value.upper()} ({best_platform[1].overall_score:.1f}/100)")
    print(f"‚ö†Ô∏è  PLATAFORMA MAIS DESAFIADORA: {worst_platform[0].value.upper()} ({worst_platform[1].overall_score:.1f}/100)")
    
    return reports


def save_comprehensive_report(reports: Dict[str, Dict[PlatformType, Any]], output_dir: Path):
    """Salva relat√≥rio comprensivo de valida√ß√£o."""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Relat√≥rio principal
    main_report = {
        "timestamp": datetime.now().isoformat(),
        "total_scripts": len(reports),
        "scripts_analyzed": {}
    }
    
    for script_name, script_reports in reports.items():
        main_report["scripts_analyzed"][script_name] = {}
        
        for platform, report in script_reports.items():
            main_report["scripts_analyzed"][script_name][platform.value] = {
                "overall_score": report.overall_score,
                "quality_level": report.quality_level.value,
                "is_approved": report.is_approved,
                "summary": report.get_summary(),
                "issues_count": len(report.all_issues),
                "critical_issues": len(report.get_critical_issues()),
                "suggestions_count": len(report.suggestions)
            }
    
    # Salva relat√≥rio principal
    main_file = output_dir / f"validation_report_{timestamp}.json"
    with open(main_file, 'w', encoding='utf-8') as f:
        json.dump(main_report, f, ensure_ascii=False, indent=2)
    
    # Salva relat√≥rios detalhados por roteiro
    for script_name, script_reports in reports.items():
        script_dir = output_dir / "detailed_reports" / script_name
        script_dir.mkdir(parents=True, exist_ok=True)
        
        for platform, report in script_reports.items():
            report_file = script_dir / f"{platform.value}_validation.json"
            
            # Converte relat√≥rio para formato serializ√°vel
            # Cria um validador tempor√°rio para serializar issues
            temp_validator = ScriptValidator()
            
            report_data = {
                "timestamp": report.timestamp.isoformat(),
                "script_title": report.script.title,
                "platform": report.platform.value,
                "overall_score": report.overall_score,
                "quality_level": report.quality_level.value,
                "is_approved": report.is_approved,
                "structure_validation": {
                    "score": report.structure_validation.score,
                    "is_valid": report.structure_validation.is_valid,
                    "issues": [temp_validator._issue_to_dict(issue) for issue in report.structure_validation.issues],
                    "suggestions": report.structure_validation.suggestions
                },
                "content_validation": {
                    "score": report.content_validation.score,
                    "is_valid": report.content_validation.is_valid,
                    "issues": [temp_validator._issue_to_dict(issue) for issue in report.content_validation.issues],
                    "suggestions": report.content_validation.suggestions
                },
                "platform_validation": {
                    "score": report.platform_validation.score,
                    "is_valid": report.platform_validation.is_valid,
                    "issues": [temp_validator._issue_to_dict(issue) for issue in report.platform_validation.issues],
                    "suggestions": report.platform_validation.suggestions
                },
                "quality_metrics": {
                    "clarity_score": report.quality_metrics.clarity_score,
                    "engagement_score": report.quality_metrics.engagement_score,
                    "retention_score": report.quality_metrics.retention_score,
                    "clarity_issues": [temp_validator._issue_to_dict(issue) for issue in report.quality_metrics.clarity_issues],
                    "engagement_issues": [temp_validator._issue_to_dict(issue) for issue in report.quality_metrics.engagement_issues],
                    "retention_issues": [temp_validator._issue_to_dict(issue) for issue in report.quality_metrics.retention_issues]
                },
                "all_issues": [temp_validator._issue_to_dict(issue) for issue in report.all_issues],
                "suggestions": report.suggestions,
                "summary": report.get_summary()
            }
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ RELAT√ìRIOS SALVOS:")
    print(f"   üìÑ Relat√≥rio principal: {main_file}")
    print(f"   üìÅ Relat√≥rios detalhados: {output_dir}/detailed_reports/")
    
    return main_file


def demonstrate_quality_insights(validator: ScriptValidator, reports: Dict[str, Dict[PlatformType, Any]]):
    """Demonstra insights sobre qualidade dos roteiros."""
    print(f"\nüîç INSIGHTS DE QUALIDADE")
    print("=" * 50)
    
    # An√°lise comparativa
    all_scores = []
    quality_levels = []
    approved_count = 0
    total_issues = 0
    
    for script_reports in reports.values():
        for report in script_reports.values():
            all_scores.append(report.overall_score)
            quality_levels.append(report.quality_level.value)
            if report.is_approved:
                approved_count += 1
            total_issues += len(report.all_issues)
    
    total_reports = len(all_scores)
    
    # Estat√≠sticas gerais
    print(f"üìä ESTAT√çSTICAS GERAIS:")
    print(f"   Total de valida√ß√µes: {total_reports}")
    print(f"   Score m√©dio: {sum(all_scores)/len(all_scores):.1f}/100")
    print(f"   Score mais alto: {max(all_scores):.1f}/100")
    print(f"   Score mais baixo: {min(all_scores):.1f}/100")
    print(f"   Roteiros aprovados: {approved_count}/{total_reports} ({approved_count/total_reports*100:.1f}%)")
    print(f"   Total de problemas encontrados: {total_issues}")
    
    # Distribui√ß√£o por n√≠vel de qualidade
    quality_distribution = {}
    for level in quality_levels:
        quality_distribution[level] = quality_distribution.get(level, 0) + 1
    
    print(f"\nüéØ DISTRIBUI√á√ÉO POR N√çVEL DE QUALIDADE:")
    for level, count in quality_distribution.items():
        percentage = count / total_reports * 100
        print(f"   {level.upper()}: {count} ({percentage:.1f}%)")
    
    # Recomenda√ß√µes gerais
    print(f"\nüí° RECOMENDA√á√ïES GERAIS:")
    
    avg_score = sum(all_scores) / len(all_scores)
    if avg_score >= 80:
        print("   ‚úÖ Qualidade geral excelente! Continue assim.")
    elif avg_score >= 60:
        print("   üü° Qualidade geral boa, mas h√° espa√ßo para melhorias.")
    else:
        print("   ‚ùå Qualidade geral precisa de aten√ß√£o. Revise a estrat√©gia.")
    
    # Identifica problemas mais comuns
    all_issues_text = []
    for script_reports in reports.values():
        for report in script_reports.values():
            all_issues_text.extend([issue.code for issue in report.all_issues])
    
    if all_issues_text:
        issue_frequency = {}
        for issue_code in all_issues_text:
            issue_frequency[issue_code] = issue_frequency.get(issue_code, 0) + 1
        
        most_common = sorted(issue_frequency.items(), key=lambda x: x[1], reverse=True)[:3]
        
        print(f"\n‚ö†Ô∏è  PROBLEMAS MAIS COMUNS:")
        for i, (issue_code, count) in enumerate(most_common, 1):
            print(f"   {i}. {issue_code}: {count} ocorr√™ncias")


def main():
    """Fun√ß√£o principal de demonstra√ß√£o."""
    print("üé¨ DEMONSTRA√á√ÉO DO SISTEMA DE VALIDA√á√ÉO DE ROTEIROS")
    print("=" * 60)
    print("AiShorts v2.0 - M√≥dulo 6: Sistema de Valida√ß√£o de Roteiro")
    print("=" * 60)
    
    # Inicializa validador
    print("\nüîß Inicializando sistema de valida√ß√£o...")
    validator = ScriptValidator()
    print("‚úÖ Validador inicializado com sucesso!")
    
    # Cria roteiros de exemplo
    print("\nüìù Preparando roteiros para valida√ß√£o...")
    scripts = create_sample_scripts()
    print(f"‚úÖ {len(scripts)} roteiros preparados!")
    
    # An√°lise individual dos roteiros
    print(f"\nüîç AN√ÅLISE DETALHADA DOS ROTEIROS")
    print("=" * 50)
    
    reports = {}
    
    for script_name, script in scripts.items():
        print(f"\nüìã Analisando: {script_name.upper().replace('_', ' ')}")
        print(f"   T√≠tulo: {script.title}")
        print(f"   Tema: {script.theme.content}")
        print(f"   Dura√ß√£o: {script.total_duration}s")
        
        # Valida√ß√£o individual (TikTok)
        single_report = demonstrate_single_platform_validation(validator, script)
        
        # Valida√ß√£o multiplataforma
        multi_reports = demonstrate_multiple_platform_validation(validator, script)
        
        reports[script_name] = multi_reports
    
    # Insights gerais
    demonstrate_quality_insights(validator, reports)
    
    # Salva relat√≥rios
    print(f"\nüíæ GERANDO RELAT√ìRIOS")
    print("=" * 30)
    
    output_dir = Path("data/validation_reports")
    main_report_file = save_comprehensive_report(reports, output_dir)
    
    # Resumo final
    print(f"\nüéâ DEMONSTRA√á√ÉO CONCLU√çDA!")
    print("=" * 40)
    print(f"‚úÖ Sistema de valida√ß√£o totalmente funcional")
    print(f"‚úÖ Valida√ß√µes para 3 plataformas (TikTok, Shorts, Reels)")
    print(f"‚úÖ An√°lise de estrutura, conte√∫do e qualidade")
    print(f"‚úÖ Gera√ß√£o autom√°tica de sugest√µes")
    print(f"‚úÖ Relat√≥rios detalhados salvos")
    print(f"\nüìÅ Relat√≥rios salvos em: {output_dir}")
    print(f"üìÑ Arquivo principal: {main_report_file.name}")
    
    print(f"\nüöÄ PR√ìXIMOS PASSOS:")
    print("   1. Integra√ß√£o com sistema de gera√ß√£o de roteiros")
    print("   2. Valida√ß√£o autom√°tica p√≥s-gera√ß√£o") 
    print("   3. Feedback loop para melhoria cont√≠nua")
    print("   4. Dashboard de m√©tricas de qualidade")


if __name__ == "__main__":
    main()
