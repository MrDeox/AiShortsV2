{"origin_pdf_path": "https://www.dafx.de/paper-archive/2024/papers/DAFx24_paper_23.pdf", "text_in_pdf": "Proceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\nA REAL-TIME APPROACH FOR ESTIMATING PULSE TRACKING PARAMETERS FOR\nBEAT-SYNCHRONOUS AUDIO EFFECTS\nPeter Meier∗Simon Schwär†Meinard Müller‡\nInternational Audio Laboratories Erlangen\nAm Wolfsmantel 33, 91058 Erlangen\nGermany\npeter.meier@audiolabs-erlangen.de\nABSTRACT\nPredominant Local Pulse (PLP) estimation, an established method\nfor extracting beat positions and other periodic pulse information\nfrom audio signals, has recently been extended with an online vari-\nant tailored for real-time applications. In this paper, we introduce\na novel approach to generating various real-time control signals\nfrom the original online PLP output. While the PLP activation\nfunction encodes both predominant pulse information and pulse\nstability, we propose several normalization procedures to discern\nlocal pulse oscillation from stability, utilizing the PLP activation\nenvelope. Through this, we generate pulse-synchronous Low Fre-\nquency Oscillators (LFOs) and supplementary confidence-based\ncontrol signals, enabling dynamic control over audio effect param-\neters in real-time. Additionally, our approach enables beat position\nprediction, providing a look-ahead capability, for example, to com-\npensate for system latency. To showcase the effectiveness of our\ncontrol signals, we introduce an audio plugin prototype designed\nfor integration within a Digital Audio Workstation (DAW), facil-\nitating real-time applications of beat-synchronous effects during\nlive mixing and performances. Moreover, this plugin serves as an\neducational tool, providing insights into PLP principles and the\ntempo structure of analyzed music signals.\n1. INTRODUCTION\nMany audio effects and instruments, such as echo, flanger, tremolo,\nor synthesizers, are often strongly aligned with the rhythmic struc-\nture of the music. This is typically achieved by modulating effect\nparameters like amplitude, frequency, or phase in a beat-synchro-\nnized way with a Low Frequency Oscillator (LFO) [1]. LFOs are\nused to generate various waveforms such as square, sawtooth, or\nsinusoidal and typically operate at frequencies below 10 Hertz, so\nthat they can enable rhythmic variations of parameters.\nThe challenge with LFO-modulated and beat-synchronous ef-\nfects lies in the manual tuning of LFO frequency and phase to\nbe in sync with the rhythmic structure of the music. In Digital\nAudio Workstations (DAWs), users often find themselves in need\nof manually adjusting parameters or drawing automation curves\nto achieve precise synchronization. This process can be time-\nconsuming and requires careful attention to detail. Similarly, in\n∗peter.meier@audiolabs-erlangen.de\n†simon.schwaer@audiolabs-erlangen.de\n‡meinard.mueller@audiolabs-erlangen.de\nCopyright: © 2024 Peter Meier et al. This is an open-access article distributed\nunder the terms of the Creative Commons Attribution 4.0 International License, which\npermits unrestricted use, distribution, adaptation, and reproduction in any medium,\nprovided the original author and source are credited.\n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 31\n01Audio(a)\n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 301Activation(b)\n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 360120180T empo (BPM)(c)\n0.000.250.500.751.00\n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 31\n01Kernels(d)\n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3\nBuffer Time (seconds)1\n01PLP\n(e)Beat\nPLP BufferFigure 1: The real-time PLP procedure is showcased utilizing a\nstraightforward drum beat as follows: (a) Audio signal. (b) Acti-\nvation function. (c) Tempogram. (d) Pulse kernels. (e) PLP func-\ntion with buffer.\nlive performance settings such as using a guitar effects pedal, mu-\nsicians must manually enter the desired tempo through tapping,\nwhich can be cumbersome and prone to human error, while there\nis also no way to dynamically react to natural tempo variations. As\na result, automating these processes can greatly enhance efficiency\nand accuracy in applying beat-related effects.\nOne method of acquiring such beat-based control parameters\nis through beat tracking (or more generally pulse tracking), which\nis an essential task in the field of Music Information Retrieval\n(MIR). Beat trackers typically proceed in two steps to identify the\ntemporal positions of beats within a music recording. They first\ncompute an activation function to expose note onset information,\nfollowed by post-processing to determine beat positions [2]. In\nrecent years, Deep Learning (DL) has driven significant advance-\nments in beat tracking, with techniques like Temporal Convolu-\ntional Networks (TCN) [3], Transformer models [4], and SpecTNT-\nTCN [5]. These methods predominantly operate in an offline mode,\nrequiring access to the complete music track for analysis.\nDAFx.1\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n314\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\nWith the increasing demand for real-time applications like in-\nteractive music systems [6] and live performance tools [7], there\nis a growing need for beat tracking algorithms capable of online\noperation. Online beat trackers have been utilized for beat-syn-\nchronous analysis in the past [8] and have recently attracted in-\ncreased interest with contributions such as BeatNet [9], Novel-1D\n[10], and BEAST-1 [11]. However, when implementing online ap-\nproaches for real-time applications or integrating them into larger\ninteractive systems, previous online beat-tracking systems often\nlack explicit control over parameters such as the tempo range of\nthe estimation or the latency of the system.\nDrawing from the Predominant Local Pulse (PLP) concept\n[12], which was originally developed for offline applications, we\nintroduced a real-time PLP tracking variant in our previous work\n[13]. This approach involves transforming the audio signal into an\nactivation function, computing a Fourier tempogram to identify lo-\ncal periodic patterns, as well as selecting and overlap-adding win-\ndowed sinusoidal kernels that represent the local pulse structure,\nas outlined in Figure 1. The PLP buffer, which is updated with\neach new frame of audio analysis, serves as a central real-time\ncomponent, reflecting both pulse oscillation and beat stability.\nAs the main contribution of this paper, we introduce a method\nto transform and normalize the real-time PLP output to derive mul-\ntiple control signals. Given that PLP is based on oscillation, with\nsinusoidal kernels representing the local pulse structure of the au-\ndio input, the PLP output closely resembles an LFO signal. We\nintroduce various normalization steps aimed at separating pulse\noscillation from stability measures. Specifically, we develop two\ndifferent confidence envelopes and two different oscillation sig-\nnals: one for a beat-synchronized LFO signal with confidence\namplitude, and another for a beat-synchronized LFO signal with\nconstant amplitude, achieved by normalizing with the confidence\nenvelope. We explore several case studies illustrating how the de-\nrived LFO and confidence parameters facilitate real-time applica-\ntions of beat-synchronous effects in live performances and mixing\nenvironments. Through these case studies, we demonstrate how\nthe derived control signals not only enable creative sound design\nbut also provide valuable insights into the tempo structure of the\naudio recording.\nThe remainder of this article is organized as follows. In Sec-\ntion 2, we investigate the real-time PLP method and its central el-\nement, the PLP buffer. Section 3 presents the normalization tech-\nniques for disentangling beat structure and estimation confidence.\nIn Section 4, we introduce four derived control signals for con-\ntrolling DAW parameters, including low frequency oscillators and\nbeat confidences. Section 5 demonstrates our method with vari-\nous applications for the four control signal variants. Finally, in\nSection 6, we conclude our contribution. Additional materials and\naudio examples are available on a supplemental website1.\n2. PREDOMINANT LOCAL PULSE\nIn this section, we introduce the main idea of the PLP algorithm as\nfirst introduced in [12]. Specifically, we summarize the real-time\nPLP procedure, as initially described in [13], and discuss the main\nproperties of the PLP buffer. This buffer serves as the centerpiece\nof the real-time PLP procedure, from which we aim to extract con-\ntrol signals.\n1https://audiolabs-erlangen.de/resources/MIR/\n2024-DAFx-RealTimePLP2.1. Real-Time PLP Procedure\nThis section summarizes the mathematical notation required for\nthis paper. For a more detailed description, we refer to [12] and\n[13]. With Figure 1, we illustrate the basic idea of the real-time\nPLP procedure. First, the audio signal (Figure 1a) is transformed\ninto an activation function ∆ :Z→R, analyzing spectral changes\nover time positions n∈Z. Note that the term activation func-\ntioncan refer to both novelty functions (such as spectral flux) and\nprobabilistic machine learning models (such as a recurrent neural\nnetwork). To detect local periodic patterns in ∆(Figure 1b), we\ncalculate a Fourier tempogram T(n, τ), which is a function over\ntime positions nand tempo parameters τ, as depicted in Figure 1c\n(for details we refer to [12]). For this purpose, we use a window2\nfunction W: [−N:N]→RforN∈N, which is normal-\nized and centered around each time position n, yielding a total\nwindow size of L= 2N+ 1. For any arbitrary but fixed time\nposition n∈Z, the window Wspecifies a neighborhood indexed\nbym∈[n−N:n+N]. For each n∈Z, we select a windowed\nsinusoidal kernel κn: [n−N:n+N]→R, given by\nκn(m) :=W(m−n)·cos\u0010\n2π\u0000\n(τn/60)·m−φn\u0001\u0011\n,(1)\nform∈[n−N:n+N], that best aligns with the periodic struc-\nture of the activation function ∆. The tempo parameter τnand\nthe corresponding phase parameter φnmaximize the tempogram\nT(n, τ), as illustrated by colored dots in Figure 1c and can be\nobtained from the complex-valued Fourier representation underly-\ning the tempogram [13]. In a real-time context, we consider n0\nas the current time position, where we only have access to the\nbeat activation values ∆(n)for all time positions n≤n0. For\nthe current time position n0, we obtain a real-time PLP function\nΓn0: [−∞:n0+N]→Rwith\nΓn0(n) :=1\nCn0X\nℓ=n−Nκℓ(n), (2)\nwhich is defined for all time positions n∈[−∞ :n0+N]and\nhas access to all kernels κℓforℓ∈[n−N:n0]. The constant\nC=NX\nn=−NW(n) (3)\nensures that the values of Γn0(n)lie within a range of [−1 : 1] .\nThe PLP buffer, depicted in Figure 1e, displays only the section of\nΓn0(n)forn∈[n0−N:n0+N], containing all the necessary\ninformation to compute the buffer for the subsequent time position.\n2.2. Extracting Control Signals from PLP Buffer\nThe PLP buffer, as introduced in Section 2.1, serves as the central\ncomponent of the real-time PLP procedure and is updated with\nthe audio data for each new current time position n0. In addition\nto encoding the local pulse structure as oscillations, it also exhibits\nvarying amplitudes, reflecting the local tempo stability of the audio\nsignal, see [12]. The reason for the varying amplitudes is that,\ndepending on the local tempo structure and the predominant tempo\nkernels selected, different kinds of interference between kernels\ncan occur, as illustrated in Figure 2.\n2We use a Hann window for all the illustrations in this paper, as well as\nfor our audio plugin prototype.\nDAFx.2\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n315\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\n-3 -2 -1 0 1 2 3100200300T empo (BPM)(a)Constructive Interference\n0.000.250.500.751.00\n-3 -2 -1 0 1 2 31\n01Kernels\n-3 -2 -1 0 1 2 3\nBuffer Time (seconds)1\n01PLP\n-3 -2 -1 0 1 2 3100200300T empo (BPM)(b)Destructive Interference\n0.000.250.500.751.00\n-3 -2 -1 0 1 2 31\n01Kernels\n-3 -2 -1 0 1 2 3\nBuffer Time (seconds)1\n01PLP\nFigure 2: The tempogram, kernels, and PLP buffer illustrate (a) constructive interference and (b) destructive interference.\nWhen the tempo situation is stable, as depicted in Figure 2a,\nthe kernels κℓselected from the tempogram Thave a similar fre-\nquency and overlap-add constructively, leading to a PLP function\nΓn0with high amplitude values. Conversely, when the tempo situ-\nation is unstable, as depicted in Figure 2b, the neighboring kernels\nexhibit significant frequency variations and cancel each other out\nin the overlapping section, resulting in a lower overall amplitude\nof the PLP function. In this way, the PLP buffer contains not only\npulse oscillation but also a beat stability measure in a single repre-\nsentation.\nOne inherent feature observed in the PLP buffer is that the val-\nues of its right half fade out to zero. This occurs because there are\nno kernels κℓavailable for overlap-adding at future time positions\nn > n 0, corresponding to diminishing confidence in pulse infor-\nmation the further one looks into the future. While this aspect is\nnot crucial for beat detection, as it has been successfully employed\nin other real-time applications before [7, 6], normalizing the PLP\nbuffer is especially necessary for extracting control signals to be\nindependent from beat confidence.\nIn the following, we address two challenges for extracting\ncontrol signals that arise from the varying amplitudes in the PLP\nbuffer. First, to achieve a more consistent oscillation, compen-\nsation for the fading amplitude within the PLP buffer should be\nenforced. Second, the pulse information should be separated into\npulse oscillation and beat stability measure. In Section 3, we will\nexamine the normalization process to bring the PLP buffer into a\nmore standardized form.\n3. NORMALIZATION\nTo address the challenges outlined in Section 2.2, in this section,\nwe explore various layers of normalization for the PLP buffer.\nFirst, in Section 3.1, we introduce a global kernel window func-\ntion, followed by a PLP envelope function in Section 3.2. Subse-\nquently, we utilize these functions to normalize the PLP buffer in\nmultiple steps, as described in Section 3.3.\n0 1 2 3 4 5 6 7 8 910 11 12\nReal Time (frames)0123AmplitudeW1\nW2\nW3\nW1+W2+W3Figure 3: An example demonstrating three shifted PLP kernel\nwindows (Hann function) contributing to an overlap-added kernel\nwindow function.\n3.1. Overlap-Add of Kernel Window Functions\nPLP is computed by adding overlapping kernels κℓ, each obtained\nby multiplying a window function Wwith a maximum amplitude\nof one. To determine the maximum possible amplitude of the PLP\nfunction Γn0, we assume perfect constructive interference of the\nshifted kernels and compute the overlap-add of the kernel window\nfunctions αn0: [n0−N:n0+N]→R, defined by\nαn0(n) :=1\nCn0X\nℓ=n−NW(n−ℓ), (4)\nforn∈[n0−N:n0+N]. The constant C, as defined in\nEquation 3, ensures that αn0lies within the range of values [0 : 1] .\nSince αn0from Equation 4 is shift invariant and does not change\nfor different values of n0, we can pre-calculate this normalization\nfunction based on the window configuration alone.\nFor demonstration purposes, in Figure 3, we illustrate only\nthree shifted and overlap-added kernel windows W1,W2, andW3\nthat combine to form a sum of kernel windows with an overall\nhigher amplitude. The exact maximum value of that sum varies\ndepending on factors such as the hop size, window length, window\ntype, and the total number of overlapping kernels. When running\na real-time PLP procedure, all of these settings are known and can\nbe pre-computed to remain constant during runtime.\nIn this way, αn0provides an important stage of the PLP buffer\nDAFx.3\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n316\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\n3\n 2\n 1\n 0 1 2 3\nBuffer Time (seconds)1.0\n0.5\n0.00.51.0PLP\nαn0Γn0\nFigure 4: The PLP function Γn0with the overlap-added kernel\nwindow function αn0indicating maximum boundaries.\n3\n 2\n 1\n 0 1 2 31\n01α-PLP(a)\nβn0Γα\nn0\n3\n 2\n 1\n 0 1 2 3\nBuffer Time (seconds)1\n01PLP(b)\nγn0Γn0\nFigure 5: (a) The α-normalized PLP function Γα\nn0with envelope\nβn0. (b) The PLP function Γn0with envelope γn0.\nnormalization, as depicted in Figure 4. The overlap-add of kernel\nwindow functions αn0acts as the upper limit of the PLP function\nΓn0across all time positions nand also dictates the shape of the\nfading amplitude within the PLP buffer for n∈[n0−N:n0+N].\nThe closer the PLP function Γn0approaches the boundaries of\nαn0, the more stable the local tempo structure of the audio is. To\nutilize the PLP buffer without the influence of the fading ampli-\ntude, we can define an α-normalized variant of Γn0, denoted by\nΓα\nn0:=Γn0\nαn0. (5)\n3.2. PLP Buffer Envelope\nAnother measure of stability is derived from the PLP function it-\nself, or more precisely, from the envelope formed by its peak po-\nsitions, as illustrated in Figure 5a. The envelope βn0of the PLP\nfunction Γα\nn0represents the magnitude of its oscillation, which can\nbe computed using the Hilbert transform [14]. The higher the value\nofβn0, the more stable the beat structure of the audio, and vice\nversa. In this way, the envelope βn0serves as a valuable analyti-\ncal tool for expressing the beat stability, particularly when the PLP\nfunction Γn0is already α-normalized. Note that, even though Γα\nn0\nfalls within the value range [−1 : 1] , this does not automatically\nguarantee that the envelope βn0is limited to the range [0 : 1] . To\nensure the desired normalization, in practice, we simply clip all\nvalues to 1where βn0>1.\n3\n 2\n 1\n 0 1 2 31\n01PLP(a)\nαn0\nγn0Γn0\n3\n 2\n 1\n 0 1 2 31\n01α-PLP(b)\nβn0Γα\nn0\n3\n 2\n 1\n 0 1 2 3\nBuffer Time (seconds)1\n01γ-PLP(c)\nΓγ\nn0Figure 6: The PLP buffer normalization in three steps: (a)\nPLP function Γn0with normalization αn0and envelope γn0.\n(b)α-normalized PLP function Γα\nn0with envelope βn0. (c) γ-\nnormalized PLP function Γγ\nn0.\nFurthermore, the combination of α- andβ-normalizations can\nalso prove to be beneficial. For instance, when using future buffer\ntime positions n > n 0, a descending slope fading to zero could\nbe advantageous to express the uncertainty of the predictions. For\nthis use case we define a second envelope\nγn0:=αn0·βn0, (6)\nas illustrated in Figure 5b. While theoretically γn0could be com-\nputed directly from the Hilbert transform of Γn0, we found that\ncleaner signals are obtained when applying α-normalization first\nto prevent values from fading to zero. This approach can reduce\nunwanted edge effects when using the Hilbert transform.\n3.3. PLP Buffer Normalization\nWith the overlap-added kernel window function αn0(Section 3.1)\nand the envelopes βn0andγn0(Section 3.2), we have multiple\nlayers for normalizing the PLP buffer Γn0, as illustrated in Fig-\nure 6.\nStarting with Figure 6a, both Γn0andαn0already fall within\nthe range of [−1 : 1] and[0 : 1] , respectively, using the constant C\nfrom Equation 3. Γn0exhibits a fading amplitude within the PLP\nbuffer, descending to values near zero, which can be compensated\nby normalizing with αn0. The resulting α-normalized PLP func-\ntionΓα\nn0is illustrated in Figure 6b. Note how the normalization\nprocess of the α-PLP is especially relevant for the right side of the\nPLP buffer, where oscillations for future time positions n > n 0are\nnow clearly visible instead of fading to zero. In this state, we can\nconsider Γα\nn0as a pulse oscillation modulated in amplitude by its\nbeat stability, which is depicted by the envelope βn0in Figure 6b.\nCombining αn0andβn0results in an envelope γn0that matches\nDAFx.4\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n317\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\n3\n 2\n 1\n 0 1 2 31\n01α-PLP(a)Stable Beat\nβn0Γα\nn0\n3\n 2\n 1\n 0 1 2 31\n01α-PLP(c)Unstable Beat\nβn0Γα\nn0\n3\n 2\n 1\n 0 1 2 3\nBuffer Time (seconds)1\n01γ-PLP(b)\nΓγ\nn0\n3\n 2\n 1\n 0 1 2 3\nBuffer Time (seconds)1\n01γ-PLP(d)\nΓγ\nn0\nFigure 7: Illustration of stable and unstable beat scenarios for α-normalized and γ-normalized PLP functions.\nΓn0, as illustrated in Figure 6a. To separate pulse oscillation from\nbeat stability measures, we can either normalize Γα\nn0with its enve-\nlopeβn0or directly normalize Γn0with its envelope γn0, which\nyields identical outputs. The resulting γ-normalized variant of the\nPLP function, denoted as Γγ\nn0, exhibits a pulse oscillation between\n[−1 : 1] with constant amplitude but without the influence of beat\nstability, as depicted in Figure 6c.\nWithαn0,βn0, andγn0, we now have multiple separate PLP\nnormalizations that offer insights into the local pulse structure in\ndifferent ways. In Figure 7, we provide two examples of how these\nnormalizations behave for stable and unstable beat tracking sce-\nnarios. A stable beat tracking scenario, as depicted in Figure 7a,\nis characterized by consistently high values for the envelope βn0,\nwith only small variations close to one. As a result, for Γγ\nn0in\nFigure 7b, we observe a highly consistent pulse curve resembling\na clean sinusoidal waveform with a regular frequency oscillation.\nAn unstable beat tracking scenario, as illustrated in Figure 7c, re-\nsults in significant fluctuation in the envelope βn0, with peak val-\nues close to zero. As a result, for Γγ\nn0in Figure 7d, we observe a\nmore inconsistent pulse curve with phase shifts indicating tempo\nchanges and a higher amount of non-regular frequency modula-\ntions.\nWith this transformation of the PLP buffer into normalized\nversions Γα\nn0andΓγ\nn0, we can derive a variety of different con-\ntrol signals, as we will discuss in Section 4.\n4. CONTROL SIGNALS\nIn Figure 8, we present an example of a real-time PLP procedure\nusing a short audio excerpt. For Figure 8a, we display the wave-\nform of the audio with a black cursor fixed at the current time\nposition n0. At this particular time position, we observe the in-\nternal state of the PLP buffer, with the current values for tem-\npogram T(n, τ), kernels κℓ(n), and PLP function Γn0(n). Note\nthat we distinguish between time axis for real time , such as the\naudio waveform, and buffer time , which serves as an internal time\nmeasure within the PLP buffer, referencing the neighborhood of\nthe current time position n0. For each time position n0, we apply\nthe normalization methods αn0,βn0, andγn0, as described in Sec-\ntion 3. From these normalizations, we can derive distinct control\nsignals, as discussed in the next subsections.4.1. Beat Confidence\nTheα-normalized PLP contributes a control signal by utilizing the\nbeat stability of the PLP function Γα\nn0. Specifically, we define beat\nconfidence at time position n0as the value of the envelope βn0at\nthe central buffer position. The resulting control signal, labeled\nβ-confidence, is depicted in Figure 8b.\nIn parallel, we can derive a similar control signal γ-confi-\ndence, which is based on Γn0and captures the value of the en-\nvelope γn0for each real time n0, as depicted in Figure 8c. The\nγ-confidence shares similarities with the β-confidence but exhibits\na lower amplitude. This characteristic could prove especially ben-\neficial if we opt to use the PLP look-ahead capability and adjust\nthe buffer read position to future or past time positions, as we will\ndiscuss in Section 4.3. In such scenarios, the γ-confidence could\neffectively represent the integration of more uncertain future pulse\ninformation, encoded with a reduced amplitude.\nTo clarify the significance of beat confidence, let’s examine\nthe audio excerpt in Figure 8a. The lowest confidence value in the\npresented audio occurs around eight seconds of real time, where\nthe music is fading out and no beat information is available. The\nsubsequent section, spanning from seconds 8 to 12, is marked by\nconsistent and rhythmic playing, resulting in a notably higher beat\nconfidence.\n4.2. Low Frequency Oscillator\nTheα-normalized PLP contributes another control signal by uti-\nlizing the pulse oscillation of the PLP function Γα\nn0. Specifically,\nwe define the low frequency oscillator α-LFO as the value of Γα\nn0\nat the central buffer position for each real time n0. The corre-\nsponding control signal is shown in Figure 8d. Additionally, from\nΓγ\nn0we can directly derive γ-LFO, which is depicted in Figure 8e.\nWhile the γ-LFO exhibits a clean, uniform oscillation between\nvalues of [−1 : 1] , the α-LFO combines both γ-LFO and β-\nconfidence, with the confidence modulated onto the signal’s am-\nplitude.\nTo explain the different behaviours of the LFOs defined, we\ncan again utilize the example in Figure 8a. Both the α-LFO and\ntheγ-LFO clearly visualize the tempo structure of the provided\nsong. At the beginning of the audio excerpt, we observe a mid-\ntempo oscillation, followed by a sudden change to a high-tempo\nDAFx.5\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n318\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\n0 2 4 6 8 10 121\n01Audio(a)Audio Input with Cursor at Time Position n0\n-3 -2 -1 0 1 2 3100200300T empo (BPM)Real-Time PLP Buffer at n0\n0 2 4 6 8 10 1201β-Conf\n(b)\n-3 -2 -1 0 1 2 31\n01Kernels\n0 2 4 6 8 10 1201γ-Conf\n(c)\n-3 -2 -1 0 1 2 31\n01PLP\n0 2 4 6 8 10 121\n01α-LFO(d)\n-3 -2 -1 0 1 2 31\n01α-PLP\n0 2 4 6 8 10 12\nReal Time (seconds)1\n01γ-LFO(e)\n-3 -2 -1 0 1 2 3\nBuffer Time (seconds)1\n01γ-PLP\nFigure 8: An audio excerpt featuring: (a) Audio input and control signals, (b) β-Conf, (c) γ-Conf, (d) α-LFO, and (e) γ-LFO. The black\ncursor indicates the current time position n0. The right side of the figure displays the inner state of the PLP buffer at that time position. An\nanimation of this audio excerpt is available on our supplemental website.\nsection around 5-8 seconds, and finishing with a low-tempo section\ntowards the end of the audio track.\n4.3. Look-ahead Capability\nFor each time position n0, we can analyze a PLP buffer where the\nleft half of the buffer shows past pulse information and the right\nhalf predicts future pulse information. This prediction is based on\nthe centered pulse kernels that drive the real-time PLP procedure\n(see Section 2.1). The central buffer position corresponds to the\ncurrent time position and is typically employed to retrieve values\nfor control signals, as described in Section 4.1 and Section 4.2.\nHowever, for the buffer read position, any buffer time can be cho-\nsen, leading to some useful and interesting time-related effects.\nFor example, by shifting the buffer read position to future time po-\nsitions, we can trigger beats earlier and obtain control signals that\noperate ahead of time, as illustrated in Figure 9.\nFor Figure 9a, we see a PLP function Γn0and two different\nbuffer read positions labeled as Cursor 1 andCursor 2 . While\nCursor 1 is positioned at the central buffer position, Cursor 2\nutilizes the look-ahead capability of real-time PLP and is shifted\nto a future time position. As a consequence, in Figure 9b, the γ-\nLFO for Cursor 2 is consistently ahead of time in oscillation and\nreaches its peaks earlier than the Cursor 1 version of the LFO.\nThis can be advantageous for two distinct reasons. First, for tech-\nnical purposes, it allows compensating for system latency effects\nand synchronizing the generated system output with the analyzed\naudio input even if the processing introduces an inherent delay.\nSecond, for creative purposes, it enables time-related effects that\nneed to start earlier to finish at the upcoming beat position, as de-\ntailed in Section 5.2. In this way, our system offers multiple ad-\njustable control signals suitable for various applications, as we will\ndiscuss in Section 5.\n1.00\n 0.75\n 0.50\n 0.25\n 0.00 0.25 0.50 0.75 1.00\nBuffer Time (seconds)1\n01PLPmove beat detection\nto future time position(a)PLP Buffer\nΓn0\nCursor 1\nCursor 2\n6.00 6.25 6.50 6.75 7.00 7.25 7.50 7.75 8.00\nReal Time (seconds)1\n01γ-LFO(b)Control Signals\nCursor 1\nCursor 2Figure 9: Demonstration of the PLP buffer with look-ahead capa-\nbility, shown with two different buffer read positions (cursors) for\ntheγ-LFO control signal.\n5. APPLICATIONS\nThe control signals α-LFO, γ-LFO, β-confidence, and γ-confi-\ndence represent musical properties of the analyzed signal which\ncan be utilized in different ways for creative mixing applications.\nTo demonstrate some use cases in a practical setting, we developed\nan audio plugin prototype with JUCE [15] (Figure 10a) that can\ngenerate the control signals in real-time from any single-channel\naudio input directly in a DAW. Since many DAWs offer the possi-\nbility to use sidechain audio signals to control the modulation of\neffect parameters (see Figure 10b for an example using REAPER\n[16]), the control signals are provided as separate audio output\nDAFx.6\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n319\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\nFigure 10: The prototype implementation and integration in REAPER: (a) The audio plugin with visualization of the real-time PLP buffer.\n(b) A sidechain audio signal for effect parameter modulation in REAPER, accessible via the menu Param > FX parameter list\n> Param modulation/MIDI link . (c) Utilizing a time-varying parameter value for effect parameter modulation.\nchannels of the plugin. Note that this method requires upsampling\nof the control signal from the frame rate (i.e., the sampling rate\nof∆) to the audio sampling rate. Alternatively, the control sig-\nnals can be made available as time-varying parameter values of\nthe plugin itself, which can be updated at frame rate and may also\nbe used as a source signal for parameter modulation in REAPER\n(see Figure 10c).\nIn addition, our implementation includes a real-time visualiza-\ntion of the current α-PLP buffer and its envelope βn0, which gives\ninsight into the current tempo structure of the analyzed music sig-\nnal. This provides both a visual indicator for current stability and\ntracked tempo octave, as well as educational value for exploring\nPLP settings. For instance, using a microphone input allows for a\ndirect exploration of how parameters such as kernel size or tempo\nrange affect PLP behavior in an intuitive way.\nIn the following, we will discuss three case studies for the\ncontrol signals, highlighting musical implications, strengths and\nlimitations of the presented approach for mixing. The examples\nare further complemented with audio excerpts on our supplemen-\ntal website.\n5.1. Case Study 1: Volume Control with Beta-Confidence\nMusically, the β-confidence control signal is high when the beat is\nstable in a musical part and low where the beat is unstable. The α-\nconfidence behaves similarly, but additionally factors in a reduced\noverall confidence when the buffer read position uses look-ahead\nand is moved into the future (since predicting future beat positions\nis inherently less reliable). In this way, both confidence signals are\nsuitable for modulating effect parameters that should vary based\non the presence of a stable beat. As an example, we may want to\nchange the volume of a pad or drone sound during a bridge part\nwhich in popular music often coincides with a change in rhythmic\npatterns and a reduction of tempo stability. Here, we use the β-\nconfidence to directly control the volume parameter of the channel.\nWe observed that a low tempo stability in the surrounding mu-\nsical part often correlates with only short decreases in the confi-\ndence control signal. To mitigate this issue, we apply minimum\nfiltering with a variable window size up to multiple seconds, so\nthat a single PLP peak with low amplitude reduces the confidence\nvalue for a larger time span. However, since the minimum filterwindow can only be applied to past confidence values in a real-\ntime setting, this may unintentionally delay the increase of confi-\ndence at the beginning of stable sections, so that the window size\nshould be balanced accordingly (see Section 5.2). After applying\nsuch modifications to the confidence, we can also generate a new\nα-LFO signal by multiplying γ-LFO with the filtered confidence.\nIn addition, while DAWs typically offer various ways to scale the\ncontrol signal for the desired use case (for example, a confidence\nof 0 could be mapped to a fader value of -15 dB and a confidence\nof 1 to 0 dB), a non-linear transformation of the confidence (like\nexponentiation with an exponent >0) may further help to achieve\nthe desired effect.\n5.2. Case Study 2: Noise Gate with Alpha-LFO\nTheα-LFO signal allows for rhythmically modulating an effect\nparameter based on the current beat estimates in sections where\nthe beat is stable, while no modulation is done in unstable parts.\nMusically, this control signal is particularly suitable for effects\nwhere the beat-synchronicity is perceptually prominent, since in\nsuch cases it may be preferable to apply no modulation instead of\na modulation that is out of sync with the music. As an example, we\ncan trigger a noise gate using α-LFO, generating a shaker-like ef-\nfect that is only present in stable beat parts. The look-ahead in the\nreal-time PLP buffer additionally allows to adjust the phase of the\nα-LFO, so that possible latencies of the entire signal processing\nchain can be compensated for. Furthermore, larger look-aheads\ncan be used to trigger an effect before the next estimated beat, e.g.\nto generate an off-beat or “reverse snare reverb” effect.\nIn this context, three limitations of the α-LFO signal may be-\ncome relevant. First, since a stable beat can only be established\nafter a few pulses have aligned, the α-LFO exhibits a “build-up”\nat the beginning of sections with a new rhythmic pattern, which\nis further intensified by minimum filtering the confidence as de-\nscribed in Section 5.1. Second, it may be desirable to freely choose\nthe tempo octave of the oscillator to control effect parameters on\nthe intended beat division level. This can be influenced to some\ndegree by the tempo range of the local tempo estimation, but a\nnarrow range may lead to unwanted instability when the desired\ntempo octave is not prominent in the analyzed input signal. Third,\nmany parameter modulations benefit from non-sinusoidal wave-\nDAFx.7\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n320\n\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24), Guildford, United Kingdom, 3 - 7 September 2024\nforms (e.g., square or sawtooth) to create the desired effect. This\nmay be achieved in future work through a non-linear transforma-\ntion of the oscillator signal.\n5.3. Case Study 3: Rhythmic Panning with Gamma-LFO\nTheγ-LFO is not scaled proportional to beat stability, so that this\ncontrol signal always utilizes the full modulation range, but may\nhave large and sudden frequency fluctuations in musical parts with\nlow tempo stability. On the other hand, this LFO signal is not af-\nfected by the confidence build-up described in Section 5.2 and can\nthus be applied for effects where using the full modulation range\nis always desirable. As an example, we use the γ-LFO to modu-\nlate the pan parameter for a channel where the recorded instrument\nplays in a steady rhythm, causing each played note to alternate be-\ntween the left and right channels. Since the panning effect is not\nas perceptually critical w.r.t. timing as for example the shaker in\nSection 5.2, some smaller inaccuracies of the γ-LFO synchroniza-\ntion do not negatively affect the outcome, but can rather lead to\ninteresting variations in the mix.\n6. CONCLUSIONS\nIn this article, we introduced a novel method for deriving pulse-\nsynchronous LFOs and supplementary confidence-based control\nsignals from a real-time PLP buffer. In this context, we discussed\nseveral normalization steps for the PLP output aimed at separat-\ning pulse oscillation from beat stability measures. We further de-\nveloped a pulse tracking audio plugin prototype, demonstrating\ncreative applications of our method, including its look-ahead ca-\npability, and offering educational insights into the real-time PLP\nprocedure. With this, our goal is to provide a practical method for\nmusicians and mixing engineers, allowing them to automate beat-\nsynchronous audio effects in live performances or to creatively uti-\nlize real-time control signals for mixing applications. For future\nresearch, we aim to conduct subjective testing to validate the case\nstudies described in this paper. Equally interesting would be an\nanalysis of listener perception to identify useful parameter settings\nfor our method.\n7. ACKNOWLEDGMENTS\nThis work was funded by the Deutsche Forschungsgemeinschaft\n(DFG, German Research Foundation) under Grant No. 500643750\n(MU 2686/15-1). The International Audio Laboratories Erlan-\ngen are a joint institution of the Friedrich-Alexander-Universität\nErlangen-Nürnberg (FAU) and Fraunhofer Institute for Integrated\nCircuits IIS.\n8. REFERENCES\n[1] Udo Zölzer, Digital Audio Signal Processing , John Wiley &\nSons, Hoboken, New Jersey, 2nd edition, 2008.\n[2] Meinard Müller, Fundamentals of Music Processing – Using\nPython and Jupyter Notebooks , Springer Verlag, 2nd edition,\n2021.\n[3] Sebastian Böck and Matthew E. P. Davies, “Deconstruct,\nanalyse, reconstruct: How to improve tempo, beat, and\ndownbeat estimation,” in Proceedings of the 21th Interna-\ntional Society for Music Information Retrieval Conference,ISMIR 2020, Montreal, Canada, October 11-16, 2020 , Julie\nCumming, Jin Ha Lee, Brian McFee, Markus Schedl, Jo-\nhanna Devaney, Cory McKay, Eva Zangerle, and Timothy\nde Reuse, Eds., 2020, pp. 574–582.\n[4] Jingwei Zhao, Gus Xia, and Ye Wang, “Beat transformer:\nDemixed beat and downbeat tracking with dilated self-\nattention,” in Proceedings of the 23rd International Society\nfor Music Information Retrieval Conference, ISMIR 2022,\nBengaluru, India, December 4-8, 2022 , 2022, pp. 169–177.\n[5] Yun-Ning Hung, Ju-Chiang Wang, Xuchen Song, Wei Tsung\nLu, and Minz Won, “Modeling beats and downbeats with a\ntime-frequency transformer,” in IEEE International Confer-\nence on Acoustics, Speech and Signal Processing, ICASSP\n2022, Virtual and Singapore, 23-27 May 2022 . 2022, pp.\n401–405, IEEE.\n[6] Peter Meier, Simon Schwär, Sebastian Rosenzweig, and\nMeinard Müller, “Real-Time MIR Algorithms for Music-\nReactive Game World Generation,” in Mensch und Computer\n2022 - Workshopband , Bonn, 2022.\n[7] Peter Meier, Gerhard Krump, and Meinard Müller, “A real-\ntime beat tracking system based on predominant local pulse\ninformation,” in Demos and Late Breaking News of the Inter-\nnational Society for Music Information Retrieval Conference\n(ISMIR) , Online, 2021.\n[8] Adam M. Stark, Matthew E. P. Davies, and Mark D. Plumb-\nley, “Real-time beat-synchronous analysis of musical audio,”\ninProceedings of the International Conference on Digital\nAudio Effects (DAFx) , Como, Italy, 2009.\n[9] Mojtaba Heydari, Frank Cwitkowitz, and Zhiyao Duan,\n“Beatnet: Crnn and particle filtering for online joint beat\ndownbeat and meter tracking,” in 22th International Society\nfor Music Information Retrieval Conference, ISMIR , 2021.\n[10] Mojtaba Heydari, Matthew McCallum, Andreas Ehmann,\nand Zhiyao Duan, “A novel 1d state space for efficient mu-\nsic rhythmic analysis,” in ICASSP 2022-2022 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal Process-\ning (ICASSP) . IEEE, 2022, pp. 421–425.\n[11] Chih-Cheng Chang and Li Su, “Beast: Online joint beat and\ndownbeat tracking based on streaming transformer,” 2024,\nAccepted by ICASSP 2024.\n[12] Peter Grosche and Meinard Müller, “Extracting predominant\nlocal pulse information from music recordings,” IEEE Trans-\nactions on Audio, Speech, and Language Processing , vol. 19,\nno. 6, pp. 1688–1701, 2011.\n[13] Peter Meier, Ching-Yu Chiu, and Meinard Müller, “A real-\ntime beat tracking system with zero latency and enhanced\ncontrollability,” Transactions of the International Society for\nMusic Information Retrieval (TISMIR) , In Review.\n[14] Julius O. Smith, Spectral Audio Signal Processing , W3K\nPublishing, http://books.w3k.org , 2011.\n[15] Raw Material Software Limited, “JUCE framework for\naudio application and plug-in development,” https://\njuce.com , 2024.\n[16] Cockos Incorporated, “REAPER digital audio workstation,”\nhttps://www.reaper.fm , 2024.\nDAFx.8\n<\n>\nProceedings of the 27thInternational Conference on Digital Audio Effects (DAFx24) Guildford, Surrey, UK, September 3-7, 2024\n321", "files_in_pdf": []}