#!/usr/bin/env python3
"""
Teste das integra√ß√µes LLM implementadas no ContentGenerationService
"""

import sys
import asyncio
from pathlib import Path
from dotenv import load_dotenv

# Adicionar src ao path
BASE_DIR = Path(__file__).resolve().parent
SRC_DIR = BASE_DIR / "src"

if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))
if str(SRC_DIR) not in sys.path:
    sys.path.insert(1, str(SRC_DIR))

# Carregar .env
load_dotenv(BASE_DIR / ".env")

from src.generators.prompt_engineering import ThemeCategory
from src.pipeline.orchestrator import AiShortsOrchestrator
from src.utils.logging_config import init_logging, get_logger, LogPerformance
from src.config.settings import config
from src.pipeline.services.content_generation_service import ContentGenerationService
from src.generators.theme_generator import ThemeGenerator
from src.generators.script_generator import ScriptGenerator
from src.utils.translator import Translator
from src.tts.kokoro_tts import KokoroTTSClient
from src.validators.script_validator import ScriptValidator

# Configurar logging
init_logging(level="INFO", log_file=f"logs/llm_test_{int(Path(__file__).stat().st_mtime)}.log")
logger = get_logger(__name__)


async def test_llm_theme_strategy():
    """Testa o LLM Theme Strategy Engine."""
    logger.info("\n" + "="*70)
    logger.info("üß† TESTANDO LLM THEME STRATEGY ENGINE")
    logger.info("="*70)
    
    # Verificar configura√ß√£o
    logger.info(f"‚úÖ Feature flag LLM Theme Strategy: {config.llm_integration.use_llm_theme_strategy}")
    
    # Criar ContentGenerationService
    theme_generator = ThemeGenerator()
    script_generator = ScriptGenerator()
    translator = Translator(api_key="", source_lang='EN', target_lang='PT', service="openrouter")
    tts_client = KokoroTTSClient()
    script_validator = ScriptValidator()
    
    content_service = ContentGenerationService(
        theme_generator=theme_generator,
        script_generator=script_generator,
        translator=translator,
        tts_client=tts_client,
        script_validator=script_validator,
        logger=logger
    )
    
    # Testar gera√ß√£o de tema com LLM
    with LogPerformance(logger, "Gera√ß√£o de tema com LLM"):
        try:
            theme, result = await content_service.generate_theme(ThemeCategory.TECHNOLOGY)
            
            logger.info(f"‚úÖ Tema gerado: {theme.content}")
            logger.info(f"üìä Qualidade: {theme.quality_score:.2f}")
            
            if theme.metadata:
                logger.info(f"üéØ Angle: {theme.metadata.get('angle', 'N/A')}")
                logger.info(f"üìà Uniqueness: {theme.metadata.get('uniqueness_score', 'N/A')}")
                logger.info(f"üî• Virality: {theme.metadata.get('virality_potential', 'N/A')}")
                logger.info(f"ü§ñ Gerado por: {theme.metadata.get('generated_by', 'N/A')}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao testar LLM Theme Strategy: {e}")
            return False


async def test_llm_script_refiner():
    """Testa o LLM Script Refiner."""
    logger.info("\n" + "="*70)
    logger.info("üß† TESTANDO LLM SCRIPT REFINER")
    logger.info("="*70)
    
    # Verificar configura√ß√£o
    logger.info(f"‚úÖ Feature flag LLM Script Refiner: {config.llm_integration.use_llm_script_refiner}")
    
    # Criar ContentGenerationService
    theme_generator = ThemeGenerator()
    script_generator = ScriptGenerator()
    translator = Translator(api_key="", source_lang='EN', target_lang='PT', service="openrouter")
    tts_client = KokoroTTSClient()
    script_validator = ScriptValidator()
    
    content_service = ContentGenerationService(
        theme_generator=theme_generator,
        script_generator=script_generator,
        translator=translator,
        tts_client=tts_client,
        script_validator=script_validator,
        logger=logger
    )
    
    # Gerar tema primeiro
    logger.info("üéØ Gerando tema para teste...")
    theme, _ = await content_service.generate_theme(ThemeCategory.SCIENCE)
    
    # Testar gera√ß√£o de script com LLM Refiner
    with LogPerformance(logger, "Gera√ß√£o de script com LLM Refiner"):
        try:
            script, result = await content_service.generate_script(
                theme=theme,
                target_platform="tiktok",
                max_attempts=2,  # Reduzir para for√ßar refinamento
                validation_threshold=80.0  # Aumentar threshold para for√ßar refinamento
            )
            
            logger.info(f"‚úÖ Script gerado e validado!")
            logger.info(f"üìä Score: {script.quality_score:.2f}")
            logger.info(f"‚è±Ô∏è Dura√ß√£o: {script.total_duration:.1f}s")
            
            if script.metadata:
                logger.info(f"üîß Refinado via LLM: {script.metadata.get('llm_refined', False)}")
                if script.metadata.get('llm_refined'):
                    logger.info(f"üîÑ Contagem de refinamentos: {script.metadata.get('refinement_count', 0)}")
                    logger.info(f"üìù Notas: {script.metadata.get('refinement_notes', [])}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao testar LLM Script Refiner: {e}")
            return False


async def main():
    """Fun√ß√£o principal de teste."""
    logger.info("=" * 70)
    logger.info("üß™ AISHORTS V2.0 - TESTE DE INTEGRA√á√ïES LLM")
    logger.info("=" * 70)
    
    # Verificar configura√ß√µes
    logger.info("\nüìã Configura√ß√µes das integra√ß√µes LLM:")
    logger.info(f"   ‚Ä¢ Theme Strategy: {config.llm_integration.use_llm_theme_strategy}")
    logger.info(f"   ‚Ä¢ Script Refiner: {config.llm_integration.use_llm_script_refiner}")
    logger.info(f"   ‚Ä¢ B-roll Planner: {config.llm_integration.use_llm_broll_planner}")
    logger.info(f"   ‚Ä¢ Reranker: {config.llm_integration.use_llm_reranker}")
    logger.info(f"   ‚Ä¢ Co-reviewer: {config.llm_integration.use_llm_co_reviewer}")
    logger.info(f"   ‚Ä¢ Caption Validator: {config.llm_integration.use_llm_caption_validator}")
    logger.info(f"   ‚Ä¢ Content Cache: {config.llm_integration.enable_content_cache}")
    logger.info(f"   ‚Ä¢ Cache TTL: {config.llm_integration.cache_ttl_hours}h")
    
    # Verificar API key
    import os
    api_key = os.getenv('OPENROUTER_API_KEY')
    if api_key:
        logger.info(f"‚úÖ API Key OpenRouter configurada: {api_key[:15]}...")
    else:
        logger.error("‚ùå OPENROUTER_API_KEY n√£o configurada!")
        return
    
    # Testar integra√ß√µes
    results = []
    
    # Testar Theme Strategy
    theme_result = await test_llm_theme_strategy()
    results.append(("Theme Strategy Engine", theme_result))
    
    # Testar Script Refiner
    script_result = await test_llm_script_refiner()
    results.append(("Script Refiner", script_result))
    
    # Resumo dos testes
    logger.info("\n" + "="*70)
    logger.info("üìä RESUMO DOS TESTES")
    logger.info("="*70)
    
    for name, success in results:
        status = "‚úÖ PASSOU" if success else "‚ùå FALHOU"
        logger.info(f"   {name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        logger.info("\nüéâ TODAS AS INTEGRA√á√ïES LLM PASSARAM NOS TESTES!")
        logger.info("\nüöÄ Para executar o pipeline completo com LLM:")
        logger.info("   python main.py")
        logger.info("   python cli_refactored.py technology")
    else:
        logger.error("\n‚ùå ALGUMAS INTEGRA√á√ïES FALHARAM. VERIFIQUE OS LOGS.")


if __name__ == "__main__":
    asyncio.run(main())